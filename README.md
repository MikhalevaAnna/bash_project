## Необходимо провести анализ логов, которые есть на сервере
Команда для генерации логов выглядит следующим образом - добавила формирование log-файла в исполняемый скрипт **analyze_logs.sh**
```
cat <<EOL > access.log
192.168.1.1 - - [28/Jul/2024:12:34:56 +0000] "GET /index.html HTTP/1.1" 200 1234
192.168.1.2 - - [28/Jul/2024:12:35:56 +0000] "POST /login HTTP/1.1" 200 567
192.168.1.3 - - [28/Jul/2024:12:36:56 +0000] "GET /home HTTP/1.1" 404 890
192.168.1.1 - - [28/Jul/2024:12:37:56 +0000] "GET /index.html HTTP/1.1" 200 1234
192.168.1.4 - - [28/Jul/2024:12:38:56 +0000] "GET /about HTTP/1.1" 200 432
192.168.1.2 - - [28/Jul/2024:12:39:56 +0000] "GET /index.html HTTP/1.1" 200 1234
EOL
```
**Написала к этому файлу с логами несколько команд:**

1. Подсчитать общее количество запросов.
2. Подсчитать количество уникальных IP-адресов. Строго с использованием awk.
3. Подсчитать количество запросов по методам (**GET**, **POST** и т.д.). Строго с использованием awk.
4. Найти самый популярный **URL**. Строго с использованием awk.
5. Создать отчет в виде текстового файла. Название текстового файла - **report.txt**
5. Результат, который должен получиться при запуске **analyze_logs.sh** следующий:
   
```   
mikhaleva@mikhaleva:~/work/log$ chmod +x analyze_logs.sh
mikhaleva@mikhaleva:~/work/log$ ./analyze_logs.sh
Отчет сохранен в файл report.txt
mikhaleva@mikhaleva:~/work/log$ cat report.txt
Отчет о логе веб-сервера
========================
Общее количество запросов:  6
Количество уникальных IP адресов:  4 


Количество запросов по методам: 
     5  GET 
     1  POST 


Самый популярный URL:  3 /index.html
```
